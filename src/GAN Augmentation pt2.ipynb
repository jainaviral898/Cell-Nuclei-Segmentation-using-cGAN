{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN Augmentation pt2.ipynb","provenance":[],"authorship_tag":"ABX9TyMkOSosxhmMeOVbwumn5ShK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pELXyDKWBrW7"},"source":["###Import Drive and Libraries"]},{"cell_type":"code","metadata":{"id":"7bZZmAgbbBav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608656902864,"user_tz":-330,"elapsed":7713,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"c5f87089-2200-4bf1-e8eb-84819566d39d"},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X_QwDDhKBkwr"},"source":["Import Google Drive"]},{"cell_type":"code","metadata":{"id":"PoQGgK0dbMfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608656925833,"user_tz":-330,"elapsed":22198,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"87f142b0-6e3e-4810-aaef-9b6663a07b51"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KSglsItqfa5G"},"source":["from zipfile import ZipFile\n","zf = ZipFile('/content/drive/Shareddrives/Aviral (B.Tech Internship)/Test-Train Split Dataset (Augmented).zip', 'r')\n","zf.extractall('/content')\n","zf.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYCHXpKbbR9g"},"source":["from zipfile import ZipFile\n","zf = ZipFile('/content/drive/Shareddrives/Aviral (B.Tech Internship)/for 30 epochs.zip', 'r')\n","zf.extractall('/content')\n","zf.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDC-ME7_Bn9y"},"source":["Import Libraries"]},{"cell_type":"code","metadata":{"id":"TnSXmTWebPfb"},"source":["import sys, cv2, glob, os \n","import numpy as np\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Activation, Conv2D, Conv2DTranspose, Dropout, Lambda, MaxPooling2D\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras import backend as K\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fz2S1YnQPxGS"},"source":["###Define GAN model "]},{"cell_type":"markdown","metadata":{"id":"CvICU6G-B1Xb"},"source":["Generator Model (Input will be RGB Images)"]},{"cell_type":"code","metadata":{"id":"46SbwsPqSS7J"},"source":["# Build Generator model (u-net)\n","inputs = Input((256,256,3))\n","s = Lambda(lambda x: x / 255) (inputs)\n","\n","c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n","c1 = Dropout(0.1) (c1)\n","c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n","p1 = MaxPooling2D((2, 2)) (c1)\n","\n","c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n","c2 = Dropout(0.1) (c2)\n","c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n","p2 = MaxPooling2D((2, 2)) (c2)\n","\n","c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n","c3 = Dropout(0.2) (c3)\n","c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n","p3 = MaxPooling2D((2, 2)) (c3)\n","\n","c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n","c4 = Dropout(0.2) (c4)\n","c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n","p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n","\n","c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n","c5 = Dropout(0.3) (c5)\n","c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n","\n","u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n","u6 = concatenate([u6, c4])\n","c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n","c6 = Dropout(0.2) (c6)\n","c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n","\n","u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n","u7 = concatenate([u7, c3])\n","c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n","c7 = Dropout(0.2) (c7)\n","c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n","\n","u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n","u8 = concatenate([u8, c2])\n","c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n","c8 = Dropout(0.1) (c8)\n","c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n","\n","u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n","u9 = concatenate([u9, c1], axis=3)\n","c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n","c9 = Dropout(0.1) (c9)\n","c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n","\n","outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n","\n","model = Model(inputs=[inputs], outputs=[outputs])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UabL2SeKCIKf"},"source":["Define Dice Loss"]},{"cell_type":"code","metadata":{"id":"7pws55TqUIgf"},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    smooth = 1\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2KcIZz99ymxU"},"source":["def D_loss:\n","\n","\n","def G_loss:\n","\n","\n","def GAN_loss:\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kzZGTTJ-B6up"},"source":["Discriminator (Input will be generated masks, and actual masks)"]},{"cell_type":"code","metadata":{"id":"4Ad_ej5qilAf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608641303319,"user_tz":-330,"elapsed":1123,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"935e0911-c267-4794-8c15-1e63a3656cd1"},"source":["def discriminator_of_images():\n","\n","    discriminator = Sequential()\n","    discriminator.add(Input(shape=(256,256,1)))\n","    discriminator.add(Conv2D(64, kernel_size=3, padding = \"same\"))\n","    discriminator.add(LeakyReLU(alpha=0.2))\n","    discriminator.add(Dropout(0.2))\n","\n","    discriminator.add(Conv2D(128, kernel_size=3,strides=(2,2), padding = \"same\"))\n","    discriminator.add(LeakyReLU(alpha=0.2))\n","    discriminator.add(Dropout(0.2))\n","\n","    discriminator.add(Conv2D(128, kernel_size=3,strides=(2,2), padding = \"same\"))\n","    discriminator.add(LeakyReLU(alpha=0.2))\n","    discriminator.add(Dropout(0.2))\n","\n","    discriminator.add(Conv2D(256, kernel_size=3, strides=(2,2), padding = \"same\"))\n","    discriminator.add(LeakyReLU(alpha=0.2))\n","    discriminator.add(Dropout(0.2))\n","\n","    discriminator.add(Flatten())\n","    discriminator.add(Dropout(0.4))\n","    discriminator.add(Dense(1, activation='sigmoid'))\n","\n","    opt = Adam(lr=0.0002 ,beta_1=0.5)\n","    discriminator.compile(loss = dice_coef_loss, optimizer = opt, metrics=[dice_coef])\n","\n","    return(discriminator)\n","\n","model_discriminator = discriminator_of_images()\n","model_discriminator.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_19 (Conv2D)           (None, 256, 256, 64)      640       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 256, 256, 64)      0         \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256, 256, 64)      0         \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 128, 128, 128)     73856     \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 128)     0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 128, 128, 128)     0         \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 64, 64, 128)       147584    \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 64, 64, 128)       0         \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 32, 32, 256)       295168    \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 262144)            0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 262144)            0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 262145    \n","=================================================================\n","Total params: 779,393\n","Trainable params: 779,393\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-mFz65YvCJ9o"},"source":["Construct GAN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcvQBn9MOwxh","executionInfo":{"status":"ok","timestamp":1608641304014,"user_tz":-330,"elapsed":1812,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"b00a9f07-2384-47a0-81be-dd520836e5e8"},"source":["def create_gan(discriminator, generator):\n","    discriminator.trainable=False\n","    gan = Sequential()\n","    gan.add(generator)\n","    gan.add(discriminator)\n","\n","    opt = Adam(lr=0.0002,beta_1=0.5) \n","    gan.compile(loss = dice_coef_loss, optimizer = opt, metrics=[dice_coef])\n","\n","    return gan\n","\n","gan = create_gan(model_discriminator,model)\n","gan.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","model (Functional)           (None, 256, 256, 1)       1941105   \n","_________________________________________________________________\n","sequential (Sequential)      (None, 1)                 779393    \n","=================================================================\n","Total params: 2,720,498\n","Trainable params: 1,941,105\n","Non-trainable params: 779,393\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R9DvUe6tb6sb"},"source":["###Load Data"]},{"cell_type":"markdown","metadata":{"id":"gTMEycrkCPK_"},"source":["Load Images and Masks (augmented dataset also imported) as numpy arrays"]},{"cell_type":"code","metadata":{"id":"BA1_sPXeEhO4"},"source":["from tensorflow import keras\n","from PIL import Image  \n","import PIL\n","import cv2\n","\n","x = []\n","train_mask_path = '/content/Test-Train Split Dataset (Augmented)/train/y'\n","for i in os.listdir(train_mask_path):\n","  newsize = (256,256,1)\n","  mask = cv2.imread(os.path.join(train_mask_path,i))\n","  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n","  x.append(mask)\n","train_mask = np.array(x)\n","\n","x = []\n","train_image_path = '/content/Test-Train Split Dataset (Augmented)/train/X'\n","for i in os.listdir(train_image_path):\n","  newsize = (256,256,1)\n","  mask = cv2.imread(os.path.join(train_image_path,i))\n","  #### delete this line\n","  x.append(mask)\n","train_image = np.array(x)\n","\n","x = []\n","test_mask_path = '/content/Test-Train Split Dataset (Augmented)/test/y'\n","for i in os.listdir(test_mask_path):\n","  newsize = (256,256)\n","  mask = cv2.imread(os.path.join(test_mask_path,i))\n","  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n","  x.append(mask)\n","test_mask = np.array(x)\n","\n","x = []\n","test_image_path = '/content/Test-Train Split Dataset (Augmented)/test/X'\n","for i in os.listdir(test_image_path):\n","  newsize = (256,256)\n","  mask = cv2.imread(os.path.join(test_image_path,i))\n","  x.append(mask)\n","test_image = np.array(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJhx5wP3at8M","executionInfo":{"status":"ok","timestamp":1608641504541,"user_tz":-330,"elapsed":870,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"94b72177-c233-47d3-d36d-56753ccd9f91"},"source":["train_mask = train_mask.reshape(510,256,256,1)\n","print(train_mask.shape)\n","train_image.shape"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(510, 256, 256, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(510, 256, 256, 3)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"5Oh67GD_xkpZ"},"source":["def generator_data_input(n_samples):        ## Gives RGB Images as input to Generator\n","  ix = np.random.randint(0, len(train_image), n_samples)\n","  X = []\n","  for i in ix:\n","    X.append(train_image[i])\n","  X = np.array(X)\n","  return X\n","\n","def create_fake_data(model_generator, n_samples):   ## Returns generated masks from the images\n","  input = generator_data_input(n_samples)\n","  X = model.predict(input)\n","  return X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H_u9vfGyCp2c"},"source":["Helper function to load data"]},{"cell_type":"code","metadata":{"id":"w5rJ06-iY0_w"},"source":["import random\n","import numpy as np\n","\n","def load_data(n_samples):\n","  ix = np.random.randint(0, len(train_mask), n_samples)\n","  X_real = []\n","  for i in ix:\n","    X_real.append(train_mask[i])\n","  X_real = np.array(X_real)\n","  y_real = np.ones((n_samples, 1))\n","  X_fake = create_fake_data(model, n_samples)\n","  y_fake = np.zeros((n_samples, 1))\n","  return X_real, y_real, X_fake, y_fake"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3X-aA1ZH23BT"},"source":["###Train Discriminator"]},{"cell_type":"code","metadata":{"id":"BP1LaG2H26_S"},"source":["def train_discriminator(model, n_iterations=100, batch = 128):\n","  medio_batch = int(batch/2)\n","\n","  for i in range(n_iterations):\n","    X_real, y_real, X_fake, y_fake = load_data(medio_batch)\n","\n","    _, acc_real = model.train_on_batch(X_real, y_real)\n","    _, acc_fake = model.train_on_batch(X_fake, y_fake)\n","\n","    print(str(i+1) + ' Real:' + str(acc_real*100) + ', Fake:' + str(acc_fake*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ikWdzON4Gqp"},"source":["Run Training"]},{"cell_type":"code","metadata":{"id":"p9RD6W0F3Uuq"},"source":["train_discriminator(model_discriminator,n_iterations=100, batch = 128)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JxsOiB5xcAI6"},"source":["###Training GAN"]},{"cell_type":"markdown","metadata":{"id":"8IHe-oGdbI0R"},"source":["Save Images"]},{"cell_type":"code","metadata":{"id":"pRKWR707aYus"},"source":["import pandas as pd\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","\n","def show_image_generated(data_fake, epoch):\n","\n","  now = datetime.now()\n","  now = now.strftime(\"%Y%m%d_%H%M%S\")\n","\n","  data_fake = (data_fake + 1) / 2.0\n","  for i in range(5):\n","    img = data_fake[i]\n","    img = img.reshape(256,256)\n","    plt.imshow(img, cmap='gray')\n","    plt.axis('off')\n","    nombre = str(epoch) + '_image_generated_' + str(i) + '.png'\n","    plt.savefig(nombre, bbox_inches='tight')\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2gDCcKVXbLqa"},"source":["Save model and evaluate model"]},{"cell_type":"code","metadata":{"id":"bVJ9B3rebDPF"},"source":["def evaluar_y_guardar(model, epoch, medio_dataset):\n","\n","  # We save the model\n","  now = datetime.now()\n","  now = now.strftime(\"%Y%m%d_%H%M%S\")\n","  nombre = str(epoch) + '_' + str(now)+\"_model\" + '.h5'\n","  model.save(nombre)\n","\n","  # We generate new data\n","  X_real, Y_real, X_fake, Y_fake = load_data(medio_dataset)\n","\n","  # We evaluate the model\n","  _, acc_real = model_discriminator.evaluate(X_real, Y_real)\n","  _, acc_fake = model_discriminator.evaluate(X_fake, Y_fake)\n","\n","  print('Acc Real:' + str(acc_real*100) + '% Acc Fake:' + str(acc_fake*100)+'%')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLd4UUJFXaco"},"source":["def TRAIN(model_generator, model_discriminator, epochs, n_batch, start = 0):\n","  medio_dataset = int(n_batch/2)\n","\n","  # We iterate over the epochs\n","  for epoch in range(start, start + epochs):\n","    # We iterate over all batches\n","    for batch in range(n_batch):\n","      # We load all the data\n","      X_real, Y_real, X_fake, Y_fake = load_data(medio_dataset)\n","\n","      # We train the discriminator \n","      cost_discriminador_real, _ = model_discriminator.train_on_batch(X_real, Y_real)\n","      \n","      cost_discriminador_fake, _ = model_discriminator.train_on_batch(X_fake, Y_fake)\n","\n","      # We generate input images for the GAN\n","      X_gan = generator_data_input(medio_dataset)\n","      Y_gan = np.ones((medio_dataset, 1))\n","\n","      # We train the GAN with fake data\n","      cost_gan = gan.train_on_batch(X_gan, Y_gan)\n","\n","    # Every 5 epochs we show the results and cost \n","    if (epoch+1) % 5 == 0:\n","      evaluar_y_guardar(model_generator,epoch = epoch, medio_dataset= medio_dataset)\n","      show_image_generated(X_fake, epoch = epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4Rb_ZqG9UQ-"},"source":["tf.config.run_functions_eagerly(True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtLiVX6BauJq"},"source":["TRAIN(model, model_discriminator, epochs = 300, n_batch=16, start = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__6LIO1Nbkmd"},"source":["###Testing"]},{"cell_type":"code","metadata":{"id":"E15shb2Ybmx-"},"source":["model.load_weights(\"/content/for 30 epochs/209_20201222_200116_model.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qmwn5fZWbva8"},"source":["import matplotlib.pyplot as plt\n","\n","results = model.predict(test_image)\n","for i in results:\n","  img = i\n","  img = img.reshape(256,256)\n","  plt.imshow(img)\n","  plt.axis('off')\n","  nombre = '_image_generated_' + str(i) + '.png'\n","  #plt.savefig(nombre, bbox_inches='tight')\n","  plt.show()\n","  plt.close()"],"execution_count":null,"outputs":[]}]}
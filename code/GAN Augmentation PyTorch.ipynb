{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN Augmentation PyTorch.ipynb","provenance":[],"collapsed_sections":["xT9Ac8X9epBO","DzTURiOW9fXp","AtfCt4zg9yVm","yZ5b-RTovmPX","QfZBIinD-BZc","0it9R0r5-WXi","KIWL6B_1l2HT","096nkaSygvqs","_tPOgin2X4Hi"],"authorship_tag":"ABX9TyPbquRjCKYGaf5w2sSAigGU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xT9Ac8X9epBO"},"source":["###Import Libraries"]},{"cell_type":"code","metadata":{"id":"3kKK-7yAZyGZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611952236873,"user_tz":-330,"elapsed":25495,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"2a9b2dde-ffb2-4876-8536-522cc7d26d61"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IuiJnBqeEOC6"},"source":["from zipfile import ZipFile\n","zf = ZipFile('/content/drive/Shareddrives/Aviral (B.Tech Internship)/nucleisegmentationbenchmark.zip', 'r')\n","zf.extractall('/content')\n","zf.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wyugPjABw6j4"},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwGGI8wdaC6-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611952245769,"user_tz":-330,"elapsed":6217,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"5ffcb7c5-ec4d-4977-d589-c1b7620d680a"},"source":["import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torch.autograd import Variable\n","from PIL import Image\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import functools\n","%pylab inline\n","import argparse\n","import os\n","import glob\n","import random\n","import numpy as np\n","import math\n","import itertools\n","import time\n","import datetime\n","import sys\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DzTURiOW9fXp"},"source":["###Parser"]},{"cell_type":"code","metadata":{"id":"WtobPebLehsV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611952245770,"user_tz":-330,"elapsed":3812,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"4d2e258d-c1cb-4faf-d75d-f1a40bb995ec"},"source":["Parser = argparse.ArgumentParser()\n","\n","Parser.add_argument('--img_height', type=int, default=512, help='size of image height')\n","Parser.add_argument('--img_width', type=int, default=512, help='size of image width')\n","Parser.add_argument('--channels', type=int, default=3, help='number of image channels')\n","Parser.add_argument('--sample_interval', type=int, default=30, help='interval between sampling of images from generators')\n","Parser.add_argument('--checkpoint_interval', type=int, default=20, help='interval between model checkpoints')\n","Parser.add_argument('--path', type=str, default=\"/content/Dataset\", help='path to code and data')\n","Parser.add_argument('--epoch', type=int, default=0, help='epoch to start training from')\n","Parser.add_argument('--n_epochs', type=int, default=50, help='number of epochs of training')\n","Parser.add_argument('--dataset_name', type=str, default=\"dataset_hist\", help='name of the dataset')\n","Parser.add_argument('--batch_size', type=int, default=5, help='size of the batches')\n","Parser.add_argument('--lr', type=float, default=0.00008, help='adam: learning rate')\n","Parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n","Parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n","Parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n","Parser.add_argument('--decay_epoch', type=int, default=40, help='epoch from which to start lr decay')\n","\n","args, _ = Parser.parse_known_args()\n","opt = Parser.parse_args(args=[])\n","print(opt)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(b1=0.5, b2=0.999, batch_size=5, channels=3, checkpoint_interval=20, dataset_name='dataset_hist', decay_epoch=40, epoch=0, img_height=512, img_width=512, lr=8e-05, n_cpu=8, n_epochs=50, path='/content/Dataset', sample_interval=30)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jfm7JLHEey0r"},"source":["### Define Models"]},{"cell_type":"code","metadata":{"id":"mMo8c0PZeVpY"},"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm2d') != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Evk7J2uGs0_"},"source":["#----------------------------------------\n","#      U-Net ++ model for Generator\n","#----------------------------------------\n","\n","class VGGBlock(nn.Module):\n","    def __init__(self, in_channels, middle_channels, out_channels):\n","        super().__init__()\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(middle_channels)\n","        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        return out\n","\n","class GeneratorUNet(nn.Module):\n","    def __init__(self, num_classes=1, input_channels=3, deep_supervision=False, **kwargs):\n","        super().__init__()\n","\n","        nb_filter = [32, 64, 128, 256, 512]\n","\n","        self.deep_supervision = deep_supervision\n","        \n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])   #3,32,32\n","        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])     #32,64,64\n","        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])     #64,128,128\n","        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])     #128,256,256\n","        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])     #256,512,512\n","\n","        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])    #96,32,32\n","        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])    #192,64,64\n","        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])    #384,128,128\n","        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])    #768,256,256\n","\n","        #self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])  #\n","        self.conv0_2 = VGGBlock(nb_filter[0], nb_filter[0], nb_filter[0])  #\n","        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n","        #self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n","        self.conv2_2 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n","\n","        #self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n","        self.conv0_3 = VGGBlock(nb_filter[0], nb_filter[0], nb_filter[0])\n","        #self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n","        self.conv1_3 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n","\n","        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n","        \n","\n","        if self.deep_supervision:\n","            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","        else:\n","            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n","\n","\n","    def forward(self, input):\n","        x0_0 = self.conv0_0(input)    #32,512,512\n","        x1_0 = self.conv1_0(self.pool(x0_0))   #64,256,256 \n","        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))    #32,512,512\n","        \n","\n","        x2_0 = self.conv2_0(self.pool(x1_0))    #128,128,128\n","        #x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))    #64,256,256\n","        #x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))    #\n","        x0_2 = self.conv0_2(x0_1)\n","\n","        x3_0 = self.conv3_0(self.pool(x2_0))\n","        #x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n","        #x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n","        x0_3 = self.conv0_3(x0_2) #\n","        \n","        x4_0 = self.conv4_0(self.pool(x3_0))\n","        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n","        #x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n","        x2_2 = self.conv2_2(torch.cat([x2_0, self.up(x3_1)], 1))\n","        #x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n","        x1_3 = self.conv1_3(torch.cat([x1_0, self.up(x2_2)], 1))\n","        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n","        \n","        \n","        if self.deep_supervision:\n","            output1 = self.final1(x0_1)\n","            output2 = self.final2(x0_2)\n","            output3 = self.final3(x0_3)\n","            output4 = self.final4(x0_4)\n","            return [output1, output2, output3, output4]\n","\n","        else:\n","            output = self.final(x0_4)\n","            return output\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4OIGS102BAZ"},"source":["\r\n","\r\n","##############################\r\n","#           U-NET\r\n","##############################\r\n","\r\n","class UNetDown(nn.Module):\r\n","    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\r\n","        super(UNetDown, self).__init__()\r\n","        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\r\n","        if normalize:\r\n","            layers.append(nn.InstanceNorm2d(out_size))\r\n","        layers.append(nn.ReLU(inplace=True))\r\n","        if dropout:\r\n","            layers.append(nn.Dropout(dropout))\r\n","        self.model = nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x):\r\n","        return self.model(x)\r\n","\r\n","class UNetUp(nn.Module):\r\n","    def __init__(self, in_size, out_size, dropout=0.0):\r\n","        super(UNetUp, self).__init__()\r\n","        layers = [nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\r\n","                    nn.InstanceNorm2d(out_size),\r\n","                    nn.ReLU(inplace=True)]\r\n","        if dropout:\r\n","            layers.append(nn.Dropout(dropout))\r\n","\r\n","        self.model = nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x, skip_input):\r\n","        x = self.model(x)\r\n","        x = torch.cat((x, skip_input), 1)\r\n","\r\n","        return x\r\n","\r\n","class GeneratorUNet(nn.Module):\r\n","    def __init__(self, in_channels=3, out_channels=1):\r\n","        super(GeneratorUNet, self).__init__()\r\n","\r\n","        self.down1 = UNetDown(in_channels, 64, normalize=False)\r\n","        self.down2 = UNetDown(64, 128)\r\n","        self.down3 = UNetDown(128, 256)\r\n","        self.down4 = UNetDown(256, 512, dropout=0.0)\r\n","        self.down5 = UNetDown(512, 512, dropout=0.0)\r\n","        self.down6 = UNetDown(512, 512, dropout=0.0)\r\n","        self.down7 = UNetDown(512, 512, dropout=0.0)\r\n","        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.0)\r\n","        self.up1 = UNetUp(512, 512, dropout=0.0)\r\n","        self.up2 = UNetUp(1024, 512, dropout=0.0)\r\n","        self.up3 = UNetUp(1024, 512, dropout=0.0)\r\n","        self.up4 = UNetUp(1024, 512, dropout=0.0)\r\n","        self.up5 = UNetUp(1024, 256)\r\n","        self.up6 = UNetUp(512, 128)\r\n","        self.up7 = UNetUp(256, 64)\r\n","\r\n","        self.final = nn.Sequential(\r\n","            nn.Upsample(scale_factor=2),\r\n","            nn.ZeroPad2d((1, 0, 1, 0)),\r\n","            nn.Conv2d(128, out_channels, 4, padding=1),\r\n","            nn.Tanh()\r\n","        )\r\n","\r\n","\r\n","    def forward(self, x):\r\n","        # U-Net generator with skip connections from encoder to decoder\r\n","        d1 = self.down1(x)\r\n","        d2 = self.down2(d1)\r\n","        d3 = self.down3(d2)\r\n","        d4 = self.down4(d3)\r\n","        d5 = self.down5(d4)\r\n","        d6 = self.down6(d5)\r\n","        d7 = self.down7(d6)\r\n","        d8 = self.down8(d7)\r\n","\r\n","        u1 = self.up1(d8, d7)\r\n","        u2 = self.up2(u1, d6)\r\n","        u3 = self.up3(u2, d5)\r\n","        u4 = self.up4(u3, d4)\r\n","        u5 = self.up5(u4, d3)\r\n","        u6 = self.up6(u5, d2)\r\n","        u7 = self.up7(u6, d1)\r\n","\r\n","        return self.final(u7)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJjIyL07Gv6G"},"source":["##############################\n","#        Discriminator\n","##############################\n","\n","class PixelDiscriminator(nn.Module):\n","    def __init__(self, input_nc=4, ndf=64, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n","        super(PixelDiscriminator, self).__init__()\n","        self.gpu_ids = gpu_ids\n","        if type(norm_layer) == functools.partial:\n","            use_bias = norm_layer.func == nn.InstanceNorm2d\n","        else:\n","            use_bias = norm_layer == nn.InstanceNorm2d\n","\n","        self.net = [\n","            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n","            norm_layer(ndf * 2),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n","            norm_layer(ndf * 4),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n","            norm_layer(ndf * 8),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=2, padding=1, bias=False)]\n","\n","        if use_sigmoid:\n","            self.net.append(nn.Sigmoid())\n","\n","        self.net = nn.Sequential(*self.net)\n","\n","    def forward(self, img_A, img_B):\n","        # Concatenate image and condition image by channels to produce input\n","        img_input = torch.cat((img_A, img_B), 1)\n","        return self.net(img_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzlRtIv-Wp4n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611952383652,"user_tz":-330,"elapsed":1973,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"798b800d-5f4b-4c01-f5ee-209dc0c38c42"},"source":["from torchsummary import summary\n","summary(generator, (3, 512, 512))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           3,072\n","              ReLU-2         [-1, 64, 256, 256]               0\n","          UNetDown-3         [-1, 64, 256, 256]               0\n","            Conv2d-4        [-1, 128, 128, 128]         131,072\n","    InstanceNorm2d-5        [-1, 128, 128, 128]               0\n","              ReLU-6        [-1, 128, 128, 128]               0\n","          UNetDown-7        [-1, 128, 128, 128]               0\n","            Conv2d-8          [-1, 256, 64, 64]         524,288\n","    InstanceNorm2d-9          [-1, 256, 64, 64]               0\n","             ReLU-10          [-1, 256, 64, 64]               0\n","         UNetDown-11          [-1, 256, 64, 64]               0\n","           Conv2d-12          [-1, 512, 32, 32]       2,097,152\n","   InstanceNorm2d-13          [-1, 512, 32, 32]               0\n","             ReLU-14          [-1, 512, 32, 32]               0\n","         UNetDown-15          [-1, 512, 32, 32]               0\n","           Conv2d-16          [-1, 512, 16, 16]       4,194,304\n","   InstanceNorm2d-17          [-1, 512, 16, 16]               0\n","             ReLU-18          [-1, 512, 16, 16]               0\n","         UNetDown-19          [-1, 512, 16, 16]               0\n","           Conv2d-20            [-1, 512, 8, 8]       4,194,304\n","   InstanceNorm2d-21            [-1, 512, 8, 8]               0\n","             ReLU-22            [-1, 512, 8, 8]               0\n","         UNetDown-23            [-1, 512, 8, 8]               0\n","           Conv2d-24            [-1, 512, 4, 4]       4,194,304\n","   InstanceNorm2d-25            [-1, 512, 4, 4]               0\n","             ReLU-26            [-1, 512, 4, 4]               0\n","         UNetDown-27            [-1, 512, 4, 4]               0\n","           Conv2d-28            [-1, 512, 2, 2]       4,194,304\n","             ReLU-29            [-1, 512, 2, 2]               0\n","         UNetDown-30            [-1, 512, 2, 2]               0\n","  ConvTranspose2d-31            [-1, 512, 4, 4]       4,194,304\n","   InstanceNorm2d-32            [-1, 512, 4, 4]               0\n","             ReLU-33            [-1, 512, 4, 4]               0\n","           UNetUp-34           [-1, 1024, 4, 4]               0\n","  ConvTranspose2d-35            [-1, 512, 8, 8]       8,388,608\n","   InstanceNorm2d-36            [-1, 512, 8, 8]               0\n","             ReLU-37            [-1, 512, 8, 8]               0\n","           UNetUp-38           [-1, 1024, 8, 8]               0\n","  ConvTranspose2d-39          [-1, 512, 16, 16]       8,388,608\n","   InstanceNorm2d-40          [-1, 512, 16, 16]               0\n","             ReLU-41          [-1, 512, 16, 16]               0\n","           UNetUp-42         [-1, 1024, 16, 16]               0\n","  ConvTranspose2d-43          [-1, 512, 32, 32]       8,388,608\n","   InstanceNorm2d-44          [-1, 512, 32, 32]               0\n","             ReLU-45          [-1, 512, 32, 32]               0\n","           UNetUp-46         [-1, 1024, 32, 32]               0\n","  ConvTranspose2d-47          [-1, 256, 64, 64]       4,194,304\n","   InstanceNorm2d-48          [-1, 256, 64, 64]               0\n","             ReLU-49          [-1, 256, 64, 64]               0\n","           UNetUp-50          [-1, 512, 64, 64]               0\n","  ConvTranspose2d-51        [-1, 128, 128, 128]       1,048,576\n","   InstanceNorm2d-52        [-1, 128, 128, 128]               0\n","             ReLU-53        [-1, 128, 128, 128]               0\n","           UNetUp-54        [-1, 256, 128, 128]               0\n","  ConvTranspose2d-55         [-1, 64, 256, 256]         262,144\n","   InstanceNorm2d-56         [-1, 64, 256, 256]               0\n","             ReLU-57         [-1, 64, 256, 256]               0\n","           UNetUp-58        [-1, 128, 256, 256]               0\n","         Upsample-59        [-1, 128, 512, 512]               0\n","        ZeroPad2d-60        [-1, 128, 513, 513]               0\n","           Conv2d-61          [-1, 1, 512, 512]           2,049\n","             Tanh-62          [-1, 1, 512, 512]               0\n","    GeneratorUNet-63          [-1, 1, 512, 512]               0\n","================================================================\n","Total params: 54,400,001\n","Trainable params: 54,400,001\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 3.00\n","Forward/backward pass size (MB): 1038.86\n","Params size (MB): 207.52\n","Estimated Total Size (MB): 1249.38\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QfZBIinD-BZc"},"source":["###Compile Model and define Loss functions"]},{"cell_type":"code","metadata":{"id":"jvuTF6Ho-Aqb"},"source":["## Check for GPU \n","cuda = True if torch.cuda.is_available() else False\n","\n","## Create Tensor type\n","if cuda:\n","  Tensor = torch.cuda.FloatTensor\n","else:\n","  Tensor = torch.FloatTensor\n","\n","## Define Loss function\n","criterion_GAN = torch.nn.MSELoss()\n","criterion_pixelwise = torch.nn.L1Loss()\n","\n","## Initialize discriminator and generator models\n","generator = GeneratorUNet()\n","discriminator = PixelDiscriminator()\n","\n","if cuda:\n","    generator = torch.nn.DataParallel(generator).cuda()\n","    discriminator = torch.nn.DataParallel(discriminator).cuda()\n","    criterion_GAN.cuda()\n","    criterion_pixelwise.cuda()\n","\n","generator.apply(weights_init_normal)\n","discriminator.apply(weights_init_normal)\n","\n","## Optimisers\n","opti_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","opti_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AtfCt4zg9yVm"},"source":["###Load Data"]},{"cell_type":"code","metadata":{"id":"tMeG6m0D9z62"},"source":["class ImageDataset(Dataset):\n","    def __init__(self, root, transforms_=None, mode='train'):\n","        self.transform = transforms.Compose(transforms_)\n","        \n","        self.files = sorted(glob.glob(os.path.join(root, mode) + '/*.*'))\n","\n","    def __getitem__(self, index):\n","\n","        img = Image.open(self.files[index % len(self.files)])\n","        width, height = img.size\n","        img_A = img.crop((0, 0, width/2, height))\n","        img_A = img_A.resize((512,512))\n","\n","        img_B = img.crop((width/2, 0, width, height))\n","        img_B = img_B.convert('L')\n","        img_B = img_B.resize((512,512))\n","        img_B = np.expand_dims(img_B, axis=-1)\n","        #\n","        seed = np.random.randint(2147483647)  # make a seed with numpy generator\n","        random.seed(seed)  # apply this seed to img tranfsorms\n","        \n","        img_A = self.transform(img_A)\n","        random.seed(seed)  # apply this seed to target tranfsorms\n","        img_B = self.transform(img_B)\n","        return {'A': img_A, 'B': img_B}\n","        \"\"\"\n","        img_A = transforms_RGB(img_A)\n","        random.seed(seed)  # apply this seed to target tranfsorms\n","        img_B = transforms_GRAY(img_B)\n","        return {'A': img_A, 'B': img_B}\n","        \"\"\"\n","\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZ5b-RTovmPX"},"source":["###Create Dataloader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TxK6H4vNvjnm","executionInfo":{"status":"ok","timestamp":1611952395802,"user_tz":-330,"elapsed":1040,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"1439a862-b29b-47aa-c814-3adf5a724830"},"source":["# Calculate output of image discriminator (PatchGAN)\n","patch = (1, opt.img_height//2**5, opt.img_width//2**5)\n","\n","# Configure dataloaders and Data Augmentation\n","train_transforms_ = [transforms.ToTensor(),\n","                     transforms.RandomVerticalFlip(p=0.5),\n","                     transforms.RandomHorizontalFlip(p=0.5),\n","                     transforms.ColorJitter(hue=0.1),\n","                     transforms.functional.rotate()]\n","\n","\n","val_transforms_ = [transforms.ToTensor()]\n","\n","dataloader = DataLoader(ImageDataset(\"/content/nucleisegmentationbenchmark/Train Images\", transforms_=train_transforms_), batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\n","print('Length of training batch is: ', len(dataloader))\n","\n","val_dataloader = DataLoader(ImageDataset(\"/content/nucleisegmentationbenchmark/Test Images\", transforms_=val_transforms_), batch_size=1, shuffle=True, num_workers=1)\n","print('Length of validation batch is: ', len(val_dataloader))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Length of training batch is:  20\n","Length of validation batch is:  24\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Usx_v1h8xkOH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611952395804,"user_tz":-330,"elapsed":1039,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"40de8b79-71bb-4a60-da1d-15241d3475d8"},"source":["\"\"\"\n","transforms_RGB = transforms.Compose(\n","    [transforms.ToTensor(),\n","    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n","    ])\n","transforms_GRAY = transforms.Compose(\n","    [transforms.ToTensor()\n","    ])\n","\n","dataloader = DataLoader(ImageDataset(\"/content/nucleisegmentationbenchmark/Train Images\", transforms_=transforms_RGB), batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\n","print('Length of training batch is: ', len(dataloader))\n","\n","val_dataloader = DataLoader(ImageDataset(\"/content/nucleisegmentationbenchmark/Test Images\", transforms_=transforms_RGB), batch_size=1, shuffle=True, num_workers=1)\n","print('Length of validation batch is: ', len(val_dataloader))\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntransforms_RGB = transforms.Compose(\\n    [transforms.ToTensor(),\\n    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\\n    ])\\ntransforms_GRAY = transforms.Compose(\\n    [transforms.ToTensor()\\n    ])\\n\\ndataloader = DataLoader(ImageDataset(\"/content/nucleisegmentationbenchmark/Train Images\", transforms_=transforms_RGB), batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\\nprint(\\'Length of training batch is: \\', len(dataloader))\\n\\nval_dataloader = DataLoader(ImageDataset(\"/content/nucleisegmentationbenchmark/Test Images\", transforms_=transforms_RGB), batch_size=1, shuffle=True, num_workers=1)\\nprint(\\'Length of validation batch is: \\', len(val_dataloader))\\n'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"0it9R0r5-WXi"},"source":["###Plots a generated sample from the validation set"]},{"cell_type":"code","metadata":{"id":"lbMOpxiV-aUU"},"source":["def sample_images(batches_done, path):\n","    #Plots histopathology image, ground truth, and generator prediction, from the validation set.\n","    images = next(iter(val_dataloader))\n","    real_A = Variable(images['A'].type(Tensor))\n","    real_B = Variable(images['B'].type(Tensor))\n","    real_A = transforms.Normalize((0.5), (0.5))(real_A)\n","    fake_B = generator(real_A)\n","    \n","    img = real_A\n","    imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\")\n","    plt.show()\n","    img = real_B\n","    imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\",cmap='gray')\n","    plt.show()\n","    img = fake_B\n","    imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\",cmap='gray')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KIWL6B_1l2HT"},"source":["###Training with new data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kn_185MOF3QSoMbbWM0m138Yz3QAxRRE"},"id":"PsxI2cQiGQK_","executionInfo":{"status":"ok","timestamp":1611948479836,"user_tz":-330,"elapsed":1139321,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"d44b298d-5f4a-4a9a-eee2-5a771670b6d2"},"source":["G_losses = []\n","D_losses = []\n","for epoch in range(opt.epoch, opt.n_epochs):\n","    for i, batch in enumerate(dataloader):\n","\n","        # ----------------------------\n","        # Model inputs, A = original histopathology image, B = ground truth binary mask\n","        # ----------------------------\n","        \n","        real_B = Variable(batch['B'].type(Tensor))\n","        real_A = Variable(batch['A'].type(Tensor))\n","        real_A = transforms.Normalize((0.5), (0.5))(real_A)\n","        ## Normalise \n","        real_B = (real_B+1.0)/2.0\n","        \n","\n","        ## Adversarial ground truth, blank tensors\n","        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False)\n","        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False)\n","\n","        # ---------------------\n","        #  TRAIN GENERATOR\n","        # ---------------------\n","\n","        opti_G.zero_grad()\n","        \n","        fake_B = generator(real_A)\n","        fake_B = (fake_B+1.0)/2.0\n","        # Loss weight of L1 pixel-wise loss between translated image and real image (lambda)\n","        lambda_ = 0.99\n","\n","        # Total G loss\n","        loss_G = (1-lambda_)*criterion_GAN(discriminator(real_A,fake_B), valid) + lambda_*criterion_pixelwise(fake_B, real_B)\n","        \n","        loss_GAN = criterion_GAN(discriminator(real_A,fake_B), valid)\n","        \n","        loss_G.backward()\n","\n","        opti_G.step()\n","\n","\n","\n","        # ------------------------\n","        #  TRAIN DISCRIMINATOR\n","        # ------------------------\n","\n","        opti_D.zero_grad()\n","\n","        # Total loss = 0.5(fake_loss+real_loss)\n","        loss_D = 0.5 * (criterion_GAN(discriminator(real_A,real_B), valid) + criterion_GAN(discriminator(real_A, fake_B.detach()), fake))\n","\n","        loss_D.backward()\n","        opti_D.step()\n","\n","\n","        #-----------------\n","        #  Log Progress\n","        #-----------------\n","\n","        batches_done = i+ len(dataloader)*epoch \n","        \n","\n","        G_losses.append(loss_G.item())\n","        D_losses.append(loss_D.item())\n","\n","        #--------------------------\n","        # Print training progress\n","        #--------------------------\n","        \n","        sys.stdout.write(\"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f] \" %\n","                                                        (epoch, opt.n_epochs,\n","                                                        i, len(dataloader),\n","                                                        loss_D.item(), loss_G.item(),\n","                                                        loss_GAN.item()))\n","        # ---------------------------------\n","        # Plot image at sample interval from validation set\n","        # ---------------------------------\n","        if batches_done % opt.sample_interval == 0:\n","            sample_images(batches_done, opt.path)\n","\n","    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n","        # -----------------------\n","        # Save model progress\n","        # -----------------------\n","        torch.save(generator.state_dict(), '/content/drive/Shareddrives/Aviral (B.Tech Internship)/Saved Training Progress/generator_29_JAN_2nd3rd Layer_%d.pth' % (epoch))\n","        torch.save(discriminator.state_dict(), '/content/drive/Shareddrives/Aviral (B.Tech Internship)/Saved Training Progress/discriminator_29_JAN_2nd3rd Layer_%d.pth' % (epoch))\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"UxxcYalhKNXC"},"source":["###See Results  "]},{"cell_type":"code","metadata":{"id":"QxDyf6cdB06y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611952503605,"user_tz":-330,"elapsed":4890,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"211afe75-0e2a-4004-d830-5e8c96a7474c"},"source":["generator.load_state_dict(torch.load('/content/drive/Shareddrives/Aviral (B.Tech Internship)/Saved Training Progress/U-net/generator_11_Jan_new_140.pth'))\n","discriminator.load_state_dict(torch.load('/content/drive/Shareddrives/Aviral (B.Tech Internship)/Saved Training Progress/U-net/discriminator_11_Jan_new_140.pth'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"I_1jgbT-YMuH"},"source":["from torchsummary import summary\n","summary(generator, (3, 512, 512))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPdgXjF0Y7UH","executionInfo":{"status":"ok","timestamp":1611952507208,"user_tz":-330,"elapsed":2163,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"376b187a-4fa8-4b07-c632-7218222085e6"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Jan 29 20:35:06 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    28W /  70W |   2105MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RWiKlMgtGi2B"},"source":["See images from test set"]},{"cell_type":"code","metadata":{"id":"gbO4Ruc7JSAp","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1onl8yota6Hyb2L2o3SpOLCUlealK1ccy"},"executionInfo":{"status":"ok","timestamp":1611582010031,"user_tz":-330,"elapsed":29025,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"67fb0e34-0091-48da-f457-723e35faf509"},"source":["for i in range(30):\n","  imgs = next(iter(val_dataloader))\n","  real_A = Variable(imgs['A'].type(Tensor))\n","  real_B = Variable(imgs['B'].type(Tensor))\n","  fake_B = generator(real_A)\n","  img = real_A\n","  imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\")\n","  plt.show()\n","  img = real_B\n","  imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\", cmap='gray')\n","  plt.show()\n","  img = fake_B\n","  imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\", cmap='gray')\n","  plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"9p9oePR-GckN"},"source":["See images from training set"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1OYTFDVQikc50CXCetBFU151xeNkZTNmz"},"id":"Zf3wga4-uCWw","executionInfo":{"status":"error","timestamp":1611576829976,"user_tz":-330,"elapsed":86102,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"e10f6dfe-41d5-407b-f703-2a8f8a48386b"},"source":["for i in range(96):\n","  imgs = next(iter(dataloader))\n","  real_A = Variable(imgs['A'].type(Tensor))\n","  real_B = Variable(imgs['B'].type(Tensor))\n","  fake_B = generator(real_A)\n","  img = real_A\n","  imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\")\n","  plt.show()\n","  img = real_B\n","  imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\", cmap='gray')\n","  plt.show()\n","  img = fake_B\n","  imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\", cmap='gray')\n","  plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"096nkaSygvqs"},"source":["###Save Generated Images"]},{"cell_type":"code","metadata":{"id":"kt_DiivwgzEM"},"source":["for i in range(96):\n","  imgs = next(iter(val_dataloader))\n","  real_A = Variable(imgs['A'].type(Tensor))\n","  real_B = Variable(imgs['B'].type(Tensor))\n","  fake_B = generator(real_A)\n","\n","  img = fake_B\n","  imgplot = plt.imsave(\"/content/new_generated_masks/test_new_UNet++_generated_\"+str(i)+\".jpg\",transforms.ToPILImage()(img[0]), cmap='gray')\n","  plt.show()\n","\n","import shutil\n","shutil.move(\"/content/new_generated_masks\",\"/content/drive/Shareddrives/Aviral (B.Tech Internship)/new generated masks/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0J_-dJWttUg"},"source":["for i in range(len(val_dataloader)):\n","  imgs = next(iter(val_dataloader))\n","  real_A = Variable(imgs['A'].type(Tensor))\n","  real_B = Variable(imgs['B'].type(Tensor))\n","  real_A = transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))(real_A[0])\n","  real_A = real_A.unsqueeze(0)\n","  fake_B = generator(real_A)\n","  \n","  GT_img = real_B\n","  GT_img = transforms.ToPILImage()(GT_img[0])\n","\n","  img = fake_B\n","  img = transforms.ToPILImage()(img[0])\n","\n","  images = [GT_img, img]\n","  widths, heights = [512,512]\n","\n","  total_width = 1024\n","  max_height = 512\n","\n","  new_im = Image.new('L', (total_width, max_height))\n","\n","  x_offset = 0\n","  for im in images:\n","    new_im.paste(im, (x_offset,0))\n","    x_offset += 512\n","\n","  new_im.save('/content/drive/Shareddrives/Aviral (B.Tech Internship)/U-Net results/'+'U-Net_test_Merged_'+str(i)+'.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_tPOgin2X4Hi"},"source":["###Performance Metrics"]},{"cell_type":"code","metadata":{"id":"2Uco8jf58RsJ","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"ok","timestamp":1611941931696,"user_tz":-330,"elapsed":2672,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"df18f9ed-07b9-4dba-df98-8b58b00da3b6"},"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(G_losses,label=\"G\")\n","plt.plot(D_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"JjjFsUzE5FyA"},"source":["Final Codes"]},{"cell_type":"code","metadata":{"id":"Zt60TC0I24mQ"},"source":["### Dice Loss (input : torch tensor)\r\n","def dice_loss(input, target):\r\n","    smooth = 1.\r\n","\r\n","    iflat = input.view(-1)\r\n","    tflat = target.view(-1)\r\n","    intersection = (iflat * tflat).sum()\r\n","    x = 1 - ((2. * intersection + smooth) /\r\n","              (iflat.sum() + tflat.sum() + smooth))\r\n","    return x\r\n","### IOU (input : torch tensor)\r\n","EPS = 1e-6\r\n","def jaccard_loss(outputs, labels):\r\n","    outputs = outputs.int()\r\n","    labels = labels.int()\r\n","    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\r\n","    union = (outputs | labels).float().sum((1, 2))  # Will be zero if both are 0\r\n","\r\n","    iou = (intersection + EPS) / (union + EPS)  # We smooth our devision to avoid 0/0\r\n","    return iou.mean()\r\n","\r\n","from sklearn.utils.extmath import cartesian\r\n","from sklearn.metrics.pairwise import pairwise_distances\r\n","from sklearn.neighbors.kde import KernelDensity\r\n","import skimage.io\r\n","\r\n","### Haussdorf Distance (input : torch tensor)\r\n","def haussdorf_distance(set1, set2, max_ahd=np.inf):\r\n","    if len(set1) == 0 or len(set2) == 0:\r\n","        return max_ahd\r\n","\r\n","    set1 = torch.squeeze(set1)\r\n","    set2 = torch.squeeze(set2)\r\n","\r\n","    set1 = torch.Tensor.cpu(set1).detach().numpy()[:, :]\r\n","    set2 = torch.Tensor.cpu(set2).detach().numpy()[:, :]\r\n","\r\n","    set1 = np.array(set1)\r\n","    set2 = np.array(set2)\r\n","\r\n","    assert set1.ndim == 2, 'got %s' % set1.ndim\r\n","    assert set2.ndim == 2, 'got %s' % set2.ndim\r\n","\r\n","    assert set1.shape[1] == set2.shape[1], \\\r\n","        'The points in both sets must have the same number of dimensions, got %s and %s.'\\\r\n","        % (set2.shape[1], set2.shape[1])\r\n","\r\n","    d2_matrix = pairwise_distances(set1, set2, metric='euclidean')\r\n","\r\n","    res = np.average(np.min(d2_matrix, axis=0)) + \\\r\n","        np.average(np.min(d2_matrix, axis=1))\r\n","\r\n","    return res\r\n","\r\n","### Surface Distances (input : numpy arrays)    \r\n","\r\n","from scipy.ndimage import _ni_support\r\n","from scipy.ndimage.morphology import distance_transform_edt, binary_erosion,\\\r\n","    generate_binary_structure\r\n","from scipy.ndimage.measurements import label, find_objects\r\n","from scipy.stats import pearsonr\r\n","\r\n","def asd(result, reference, voxelspacing=None, connectivity=1):\r\n","    \r\n","    sds = __surface_distances(result, reference, voxelspacing, connectivity)\r\n","    asd = sds.mean()\r\n","    return asd\r\n","\r\n","\r\n","def assd(result, reference, voxelspacing=None, connectivity=1):\r\n","    \"\"\"\r\n","    Average symmetric surface distance.\r\n","    \"\"\"\r\n","    \r\n","\r\n","    assd = numpy.mean( (asd(result, reference, voxelspacing, connectivity), asd(reference, result, voxelspacing, connectivity)) )\r\n","    return assd\r\n","\r\n","def __surface_distances(result, reference, voxelspacing=None, connectivity=1):\r\n","\r\n","\r\n","    result = numpy.atleast_1d(result.astype(numpy.bool))\r\n","    reference = numpy.atleast_1d(reference.astype(numpy.bool))\r\n","    if voxelspacing is not None:\r\n","        voxelspacing = _ni_support._normalize_sequence(voxelspacing, result.ndim)\r\n","        voxelspacing = numpy.asarray(voxelspacing, dtype=numpy.float64)\r\n","        if not voxelspacing.flags.contiguous:\r\n","            voxelspacing = voxelspacing.copy()\r\n","            \r\n","    # binary structure\r\n","    footprint = generate_binary_structure(result.ndim, connectivity)\r\n","    \r\n","    # test for emptiness\r\n","    if 0 == numpy.count_nonzero(result): \r\n","        raise RuntimeError('The first supplied array does not contain any binary object.')\r\n","    if 0 == numpy.count_nonzero(reference): \r\n","        raise RuntimeError('The second supplied array does not contain any binary object.')    \r\n","            \r\n","    # extract only 1-pixel border line of objects\r\n","    result_border = result ^ binary_erosion(result, structure=footprint, iterations=1)\r\n","    reference_border = reference ^ binary_erosion(reference, structure=footprint, iterations=1)\r\n","    \r\n","    # compute average surface distance        \r\n","    # Note: scipys distance transform is calculated only inside the borders of the\r\n","    #       foreground objects, therefore the input has to be reversed\r\n","    dt = distance_transform_edt(~reference_border, sampling=voxelspacing)\r\n","    sds = dt[result_border]\r\n","    \r\n","    return sds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkcgaTpP1fHr"},"source":["eval_dataloader_train = DataLoader(ImageDataset(\"/content/drive/Shareddrives/Aviral (B.Tech Internship)/U-Net results/Train\", transforms_=train_transforms_), batch_size=1, shuffle=True, num_workers=opt.n_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lb70KyYIYbkF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611953594676,"user_tz":-330,"elapsed":14946,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"f6f60dcb-87e3-4000-e21a-1e09058d44fc"},"source":["iou_list = []\n","dice_list = []\n","hausdorff_list = []\n","assd_list = []\n","asd_list = []\n","\n","for i in range(len(eval_dataloader_train)):\n","  imgs = next(iter(eval_dataloader_train))\n","  real_A = Variable(imgs['A'].type(Tensor))\n","  real_B = Variable(imgs['B'].type(Tensor))\n","  fake_B = real_A\n","  \n","  #print(real_A.shape)\n","  #print(real_B.shape)\n","  #print(fake_B.shape)\n","\n","  real_B = (real_B+1.0)/2.0\n","  fake_B = (fake_B+1.0)/2.0\n","  real_B = transforms.Normalize((0.5),(0.5))(real_B)\n","  fake_B = transforms.Normalize((0.5),(0.5))(fake_B)\n","  \n","\n","  num = jaccard_loss(fake_B, real_B)\n","  iou_list.append(num)\n","  \n","  num = dice_loss(fake_B, real_B)\n","  dice_list.append(num)\n","\n","  num = haussdorf_distance(fake_B, real_B)\n","  hausdorff_list.append(num)\n","\n","  real_B = torch.squeeze(real_B)\n","  fake_B = torch.squeeze(fake_B)\n","\n","  real_B = torch.Tensor.cpu(real_B).detach().numpy()[:, :]\n","  fake_B = torch.Tensor.cpu(fake_B).detach().numpy()[:, :]\n","\n","  num = asd(fake_B, real_B)\n","  asd_list.append(num)\n","\n","  num = assd(fake_B, real_B)\n","  assd_list.append(num)\n","  \n","  real_A = None\n","  real_B = None\n","  fake_B = None\n","  torch.cuda.empty_cache()\n","\n","##----------------------------------------------------------------------------------------------------------------------------------------------\n","print('\\n\\n\\n-------------------------------------------')\n","print('-----Performance Metrics on Train set------\\n')\n","print('IOU = '                                  +str(torch.mean(torch.stack(iou_list))))\n","print('Dice = '                                 +str(torch.mean(torch.stack(dice_list))))\n","print('Haussdorf = '                            +str(np.mean(hausdorff_list)))\n","print('Average Surface Symmetric Distance = '   +str(np.mean(assd_list)))\n","print('Average Surface Distance = '             +str(np.mean(asd_list)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","-------------------------------------------\n","-----Performance Metrics on Train set------\n","\n","IOU = tensor(0.1864, device='cuda:0')\n","Dice = tensor(0.6551, device='cuda:0')\n","Haussdorf = 7.824056\n","Average Surface Symmetric Distance = 1.7415308770258016\n","Average Surface Distance = 0.5218544098588527\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nycAEgXY6lAC"},"source":["eval_dataloader_test = DataLoader(ImageDataset(\"/content/drive/Shareddrives/Aviral (B.Tech Internship)/U-Net results/Test\", transforms_=train_transforms_), batch_size=1, shuffle=True, num_workers=opt.n_cpu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxL0Lf3ZtcbO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611953907747,"user_tz":-330,"elapsed":16010,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"19f74af2-41ef-4b3e-a21d-055cb866751e"},"source":["iou_list_test = []\n","dice_list_test = []\n","hausdorff_list_test = []\n","surfd_list_test = []\n","assd_list_test = []\n","asd_list_test = []\n","\n","for i in range(24):\n","  imgs = next(iter(eval_dataloader_test))\n","  real_A = Variable(imgs['A'].type(Tensor))\n","  real_B = Variable(imgs['B'].type(Tensor))\n","  fake_B = real_A\n","\n","  real_B = (real_B+1.0)/2.0\n","  fake_B = (fake_B+1.0)/2.0\n","  real_B = transforms.Normalize((0.5),(0.5))(real_B)\n","  fake_B = transforms.Normalize((0.5),(0.5))(fake_B)\n","  \n","  num = jaccard_loss(fake_B, real_B)\n","  iou_list_test.append(num)\n","  \n","  num = dice_loss(fake_B, real_B)\n","  dice_list_test.append(num)\n","\n","  num = haussdorf_distance(fake_B, real_B)\n","  hausdorff_list_test.append(num)\n","\n","  real_B = torch.squeeze(real_B)\n","  fake_B = torch.squeeze(fake_B)\n","\n","  real_B = torch.Tensor.cpu(real_B).detach().numpy()[:, :]\n","  fake_B = torch.Tensor.cpu(fake_B).detach().numpy()[:, :]\n","\n","  num = asd(fake_B, real_B)\n","  asd_list_test.append(num)\n","  \n","  num = assd(fake_B, real_B)\n","  assd_list_test.append(num)\n","  \n","  real_A = None\n","  real_B = None\n","  fake_B = None\n","  torch.cuda.empty_cache()\n","\n","##---------------------------------------------------------------------\n","\n","print('\\n\\n\\n-------------------------------------------')\n","print('-----Performance Metrics on Test set-----\\n')\n","print('IOU = '                                  +str(torch.mean(torch.stack(iou_list_test))))\n","print('Dice = '                                 +str(torch.mean(torch.stack(dice_list_test))))\n","print('Haussdorf = '                            +str(np.mean(hausdorff_list_test)))\n","print('Average Surface Symmetric Distance = '   +str(np.mean(assd_list_test)))\n","print('Average Surface Distance = '             +str(np.mean(asd_list_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","-------------------------------------------\n","-----Performance Metrics on Test set-----\n","\n","IOU = tensor(0.0737, device='cuda:0')\n","Dice = tensor(0.7812, device='cuda:0')\n","Haussdorf = 8.550956\n","Average Surface Symmetric Distance = 4.757861492989718\n","Average Surface Distance = 0.841579037983217\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jk-5ENEwqURf"},"source":["torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vkohRo3AeP7_"},"source":["###Playground"]},{"cell_type":"code","metadata":{"id":"YD4jDV84OX7-"},"source":["class try_ImageDataset(Dataset):\n","    def __init__(self, root, transforms_=None, mode='train'):\n","        self.transform = transforms_\n","        \n","        self.files = sorted(glob.glob(os.path.join(root, mode) + '/*.*'))\n","\n","    def __getitem__(self, index):\n","\n","        img = Image.open(self.files[index % len(self.files)])\n","        width, height = img.size\n","        img_A = img.crop((0, 0, width/2, height))\n","        img_A = img_A.resize((512,512))\n","\n","        img_B = img.crop((width/2, 0, width, height))\n","        img_B = img_B.convert('L')\n","        img_B = img_B.resize((512,512))\n","        img_B = np.expand_dims(img_B, axis=-1)\n","        #\n","        seed = np.random.randint(2147483647)  # make a seed with numpy generator\n","        random.seed(seed)  # apply this seed to img transfsorms\n","        img_A = try_transforms_1(img_A)\n","        random.seed(seed)  # apply this seed to target transfsorms\n","        img_B = try_transforms_2(img_B)\n","        return {'A': img_A, 'B': img_B}\n","\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8j28d-RIRza","executionInfo":{"status":"ok","timestamp":1611573947438,"user_tz":-330,"elapsed":2245,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"8c80e980-c6fe-4b07-cd91-ebaaa2e308f6"},"source":["try_transforms_1 = transforms.Compose([transforms.ToTensor(),\n","                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n","try_transforms_2 = transforms.Compose([transforms.ToTensor()])\n","                #transforms.Normalize((0.5), (0.5))]\n","try_transforms_ = [try_transforms_1, try_transforms_2]\n","try_dataloader = DataLoader(try_ImageDataset(\"/content/nucleisegmentationbenchmark/Train Images\", transforms_=None), batch_size=1, shuffle=True, num_workers=opt.n_cpu)\n","print('Length of training batch is: ', len(dataloader))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Length of training batch is:  20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yXoAGQZ6bxKr"},"source":["imgs = next(iter(val_dataloader))\n","real_A = Variable(imgs['A'].type(Tensor))\n","real_B = Variable(imgs['B'].type(Tensor))\n","fake_B = generator(real_A)\n","real_A = transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))(real_A[0])\n","real_A = real_A.unsqueeze(0)\n","print(real_A.shape)\n","real_B = (real_B+1.0)/2.0\n","fake_B = (fake_B+1.0)/2.0\n","\n","\"\"\"\n","img = real_A\n","imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\")\n","plt.show()\n","img = real_B\n","imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\", cmap='gray')\n","plt.show()\n","img = fake_B\n","imgplot = plt.imshow(transforms.ToPILImage()(img[0]), interpolation=\"bicubic\", cmap='gray')\n","plt.show()\n","\n","print('IOU = ' + str(jc(fake_B, real_B)) )\n","print('Dice = '+ str(dc(fake_B, real_B)) )\n","print('hd  = = = '+str(hd1111(fake_B, real_B)))\n","\n","real_B = torch.squeeze(real_B)\n","fake_B = torch.squeeze(fake_B)\n","\n","real_B = torch.Tensor.cpu(real_B).detach().numpy()[:, :]\n","fake_B = torch.Tensor.cpu(fake_B).detach().numpy()[:, :]\n","\n","\n","print('hausdorff = '+str(hd(fake_B,real_B)))\n","print('IOU ===== ' + str(iou(fake_B, real_B)) )\n","print('Dice ===== ' + str(dice(fake_B, real_B)) )\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Up4dIm2MLtuI"},"source":["real_A = None\n","real_B = None\n","fake_B = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJRhrNk_cYXS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611954126430,"user_tz":-330,"elapsed":1727,"user":{"displayName":"Aviral Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpqxTI0oZAV6sffna6v0nwfnpdnPOJCf_uaTe_XAM=s64","userId":"05305286875266982149"}},"outputId":"7ccc2ca0-7a76-4976-e8d6-094998dcc2ba"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Jan 29 21:02:05 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    28W /  70W |   1191MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"etOPOW7ruaJD"},"source":[""],"execution_count":null,"outputs":[]}]}
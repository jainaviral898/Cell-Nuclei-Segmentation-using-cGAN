{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mask Classifier.ipynb","provenance":[],"authorship_tag":"ABX9TyNdL3y/OaqKA+Yp7T2P97Kd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dzwzdnO3P6X-"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9xJMQA6P7HE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SmREVjMnPwsz"},"source":["import argparse\n","import os\n","import glob\n","import random\n","import numpy as np\n","import math\n","import itertools\n","import time\n","import datetime\n","import sys\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torch.autograd import Variable\n","from PIL import Image\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import functools\n","%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vwsBfuo5JuX"},"source":["#Import data for training (masks)\r\n","#If generated masks are being used for training, then use clustering.\r\n","#If original masks are being used, then use CNN with labeled data.\r\n","x_train = "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDpA5Z8rWAQl"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.ImageFolder(root='./data', transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', transform=transform)\n","\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)\n","\n","classes = ('benign','malignant')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qn3uQshwW2Kb"},"source":["def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VisGs3R6-ekJ"},"source":["from torchsummary import summary\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()\n","\n","summary(net, (3, 512, 512))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzX3-oQmRknZ"},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"code","id":"B1R_fBmQRqr4"},"source":["#@title Default title text\n","for epoch in range(2):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","PATH = '/content/cifar_net.pth'\n","torch.save(net.state_dict(), PATH)"],"execution_count":null,"outputs":[]}]}